# SIEM System Project Overview

## 1. Objective

The project aims to develop a **Security Information and Event Management (SIEM)** system for real-time monitoring and analysis of security events. It focuses on handling logs received through UDP, parsing them, and storing them in a **MongoDB** database.

Additionally, the project integrates **anomaly detection** using machine learning to identify suspicious activities in real-time.

## 2. Components

### UDP Server (`server.py`)
- **Functionality:**
  - Listens for logs on a specified UDP port.
  - Rotates between two log files (`window_logs.csv` and `window_logs2.csv`) to manage log storage.
  - Parses incoming logs and writes them to the respective log file.

### Parser (`parsing.py`)
- **Functionality:**
  - Parses logs from different sources (Linux and Mac logs in this case).
  - Extracts relevant fields using regular expressions.
  - Inserts parsed data into a MongoDB database (`project_db`).

### Anomaly Detection (Machine Learning Integration)
- **Objective:**
  - Leverages machine learning models to detect **anomalous patterns** in the log data.
  - Detects unusual events that may indicate security breaches, system failures, or other irregularities.
  
- **Workflow:**
  - Parsed logs are analyzed using machine learning models like **Isolation Forest**, **One-Class SVM**, or **LSTM-based** models for sequential data.
  - The system flags suspicious logs for further investigation or triggers alerts.
  
- **Model Training:**
  - **Training Data:** Historical log data is used to train the models, classifying normal and abnormal patterns.
  - **Features:** Log fields like timestamp, event type, source IP, and error codes serve as features for the model.

- **Deployment:**
  - The model is deployed as part of the backend to continuously monitor new incoming logs for anomalies.
  - Anomalous logs are highlighted in the frontend for easy identification by users.

### Frontend 
- The frontend is developed using **React.js**.
- It will provide a user-friendly interface for interacting with the parsed and flagged logs.
- Users can:
  - View logs,
  - Apply filters,
  - Analyze flagged anomalies,
  - and perform other actions through the UI.

### Backend 
- The backend is developed using **Node.js** and **Express.js**.
- It will handle communication with the **MongoDB** database.
- Provides API endpoints for the frontend to fetch and interact with both parsed log data and flagged anomalies.

## 3. Flow of Data
1. Logs are generated by various sources and sent over **UDP** to the server.
2. The **UDP server (`server.py`)** receives logs, rotates log files, and parses them using regular expressions.
3. Parsed logs are inserted into a **MongoDB** database using the **parser (`parsing.py`)**.
4. Machine learning models analyze the logs for anomalies and flag suspicious events.
5. The frontend interacts with the backend to fetch log data from the database and provides a user interface for users to visualize and analyze the logs, including flagged anomalies.

## 4. Improvements
- Introduce **multithreading** for concurrent log processing.
- Implement a more structured and modular code architecture.
- Enhance security measures and error handling.
- Continuously improve the anomaly detection models by:
  - Using more advanced algorithms or deep learning techniques.
  - Refining features for better detection accuracy.
  - Implementing model retraining based on newly flagged anomalies.

---

## File Descriptions

### 1. `server.py`
This file acts as the **UDP server** that receives logs and manages the rotation of log files.

#### Key Concepts:
- **Socket Programming:** Uses the `socket` module to create a **UDP socket**.
- **File Handling:** Writes incoming logs to rotating log files (`window_logs.csv` and `window_logs2.csv`).
- **Infinite Loop:** Continuously listens for incoming logs in an infinite loop.

#### Possible Improvements:
- Enhance **error handling** to handle exceptions more gracefully.
- Modularize the code further for better maintainability.

### 2. `parsing.py`
This file is responsible for **parsing logs** and inserting them into a **MongoDB** database.

#### Key Concepts:
- **Regular Expressions:** Utilizes regular expressions to extract relevant fields from logs.
- **MongoDB Interaction:** Uses the `pymongo` library to interact with a **MongoDB** database.
- **Error Handling:** Catches exceptions during parsing to ensure smooth execution.

#### Possible Improvements:
- Modularize the code further for better readability.
- Add comments to explain complex sections for better understanding.

### 3. `parsing_mac_linux.py`
This file provides similar functionality to `parsing.py` but is tailored for **Mac** and **Linux** logs.

#### Key Concepts:
- Similar to `parsing.py` but with specific regular expressions tailored for **Mac** and **Linux** logs.

#### Possible Improvements:
- Consider merging the functionalities of `parsing.py` and `parsing_mac_linux.py` into a single, more versatile parser.
- Ensure consistent code structure and naming conventions.

---

## 5. Machine Learning Integration

- **Models Used:** Common anomaly detection models such as:
  - **Isolation Forest**
  - **One-Class SVM**
  - **LSTM** for time-series analysis
- **Training:** Using historical log data to distinguish between normal and abnormal patterns.
- **Deployment:** Continuously monitors logs in real-time and flags suspicious activities.

#### Future Enhancements:
- Implement adaptive learning to refine the anomaly detection models based on real-time feedback.
- Integrate visualization tools in the frontend for displaying flagged anomalies and insights.
